[
  {
    "objectID": "CS5805.html",
    "href": "CS5805.html",
    "title": "CS5805",
    "section": "",
    "text": "The blog posts presented here are created as part of the requirmetns for CS5805 offerd for fall 24 at Virginia Tech. More infomration about me can be found on my personal website"
  },
  {
    "objectID": "posts/pca.html",
    "href": "posts/pca.html",
    "title": "Principal Component Analysis",
    "section": "",
    "text": "Banner Image Credit: Jernej Furman\nPrincipal component analysis (PCA) is a popular technique for analyzing large datasets containing a high number of dimensions/features per observation, increasing the interpretability of data while preserving the maximum amount of information, and enabling the visualization of multidimensional data.\nFormally, PCA is a statistical technique for reducing the dimensionality of a dataset. This is accomplished by linearly transforming the data into a new coordinate system where (most of) the variation in the data can be described with fewer dimensions than the initial data. Many studies use the first two principal components in order to plot the data in two dimensions and to visually identify clusters of closely related data points. Principal component analysis has applications in many fields such as population genetics, microbiome studies, and atmospheric science."
  },
  {
    "objectID": "posts/regression.html",
    "href": "posts/regression.html",
    "title": "Linear and nonlinear regression",
    "section": "",
    "text": "Adipisicing sunt nisi nulla pariatur ex ipsum mollit. Dolor commodo cillum sint amet commodo. Nulla culpa aliqua enim ad anim. Aliquip ex duis minim laborum enim aliquip ad aliqua. Sit consectetur excepteur ea aliqua exercitation Lorem ex elit incididunt consequat ea. Excepteur qui velit commodo non cillum enim duis occaecat laborum tempor sint do anim. In nostrud ex aliqua commodo sunt quis velit. Enim laborum officia officia nostrud sunt velit dolore Lorem occaecat ipsum.\nPariatur mollit in eiusmod irure velit veniam aliquip tempor culpa minim. Nulla proident eiusmod ipsum aute eiusmod aliqua. Amet cupidatat adipisicing nostrud exercitation amet anim aliqua sint mollit in dolor culpa. Adipisicing nostrud culpa excepteur ullamco. Eiusmod eu laboris excepteur sint eu excepteur et. Ullamco eu cupidatat consectetur fugiat minim fugiat sunt ut minim. Pariatur dolor exercitation sunt ipsum Lorem velit sit Lorem laboris Lorem.\nQui Lorem fugiat do commodo exercitation anim commodo incididunt sint aute deserunt nulla. Ex incididunt do ut ullamco exercitation in laborum cupidatat. Dolor laboris cupidatat anim sint. Culpa elit voluptate officia ex elit ullamco fugiat pariatur mollit labore eiusmod id anim."
  },
  {
    "objectID": "posts/clustering.html",
    "href": "posts/clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "Banner Image Credit: University of Rochester\nAdipisicing sunt nisi nulla pariatur ex ipsum mollit. Dolor commodo cillum sint amet commodo. Nulla culpa aliqua enim ad anim. Aliquip ex duis minim laborum enim aliquip ad aliqua. Sit consectetur excepteur ea aliqua exercitation Lorem ex elit incididunt consequat ea. Excepteur qui velit commodo non cillum enim duis occaecat laborum tempor sint do anim. In nostrud ex aliqua commodo sunt quis velit. Enim laborum officia officia nostrud sunt velit dolore Lorem occaecat ipsum.\nPariatur mollit in eiusmod irure velit veniam aliquip tempor culpa minim. Nulla proident eiusmod ipsum aute eiusmod aliqua. Amet cupidatat adipisicing nostrud exercitation amet anim aliqua sint mollit in dolor culpa. Adipisicing nostrud culpa excepteur ullamco. Eiusmod eu laboris excepteur sint eu excepteur et. Ullamco eu cupidatat consectetur fugiat minim fugiat sunt ut minim. Pariatur dolor exercitation sunt ipsum Lorem velit sit Lorem laboris Lorem.\nQui Lorem fugiat do commodo exercitation anim commodo incididunt sint aute deserunt nulla. Ex incididunt do ut ullamco exercitation in laborum cupidatat. Dolor laboris cupidatat anim sint. Culpa elit voluptate officia ex elit ullamco fugiat pariatur mollit labore eiusmod id anim."
  },
  {
    "objectID": "posts/classification.html",
    "href": "posts/classification.html",
    "title": "Classification",
    "section": "",
    "text": "Banner Image Credit: Jernej Furman\nAdipisicing sunt nisi nulla pariatur ex ipsum mollit. Dolor commodo cillum sint amet commodo. Nulla culpa aliqua enim ad anim. Aliquip ex duis minim laborum enim aliquip ad aliqua. Sit consectetur excepteur ea aliqua exercitation Lorem ex elit incididunt consequat ea. Excepteur qui velit commodo non cillum enim duis occaecat laborum tempor sint do anim. In nostrud ex aliqua commodo sunt quis velit. Enim laborum officia officia nostrud sunt velit dolore Lorem occaecat ipsum.\nPariatur mollit in eiusmod irure velit veniam aliquip tempor culpa minim. Nulla proident eiusmod ipsum aute eiusmod aliqua. Amet cupidatat adipisicing nostrud exercitation amet anim aliqua sint mollit in dolor culpa. Adipisicing nostrud culpa excepteur ullamco. Eiusmod eu laboris excepteur sint eu excepteur et. Ullamco eu cupidatat consectetur fugiat minim fugiat sunt ut minim. Pariatur dolor exercitation sunt ipsum Lorem velit sit Lorem laboris Lorem.\nQui Lorem fugiat do commodo exercitation anim commodo incididunt sint aute deserunt nulla. Ex incididunt do ut ullamco exercitation in laborum cupidatat. Dolor laboris cupidatat anim sint. Culpa elit voluptate officia ex elit ullamco fugiat pariatur mollit labore eiusmod id anim."
  },
  {
    "objectID": "posts/post5.html",
    "href": "posts/post5.html",
    "title": "Setup",
    "section": "",
    "text": "Chapter 1 – The Machine Learning landscape\nThis notebook contains the code examples in chapter 1. You’ll also find the exercise solutions at the end of the notebook. The rest of this notebook is used to generate lifesat.csv from the original data sources, and some of this chapter’s figures.\nYou’re welcome to go through the code in this notebook if you want, but the real action starts in the next chapter.\nThis project requires Python 3.7 or above:\nimport sys\n\nassert sys.version_info &gt;= (3, 7)\nScikit-Learn ≥1.0.1 is required:\nfrom packaging import version\nimport sklearn\n\nassert version.parse(sklearn.__version__) &gt;= version.parse(\"1.0.1\")\nLet’s define the default font sizes, to plot pretty figures:\nimport matplotlib.pyplot as plt\n\nplt.rc('font', size=12)\nplt.rc('axes', labelsize=14, titlesize=14)\nplt.rc('legend', fontsize=12)\nplt.rc('xtick', labelsize=10)\nplt.rc('ytick', labelsize=10)\nMake this notebook’s output stable across runs:\nimport numpy as np\n\nnp.random.seed(42)"
  },
  {
    "objectID": "posts/post5.html#load-and-prepare-life-satisfaction-data",
    "href": "posts/post5.html#load-and-prepare-life-satisfaction-data",
    "title": "Setup",
    "section": "Load and prepare Life satisfaction data",
    "text": "Load and prepare Life satisfaction data\nTo create lifesat.csv, I downloaded the Better Life Index (BLI) data from OECD’s website (to get the Life Satisfaction for each country), and World Bank GDP per capita data from OurWorldInData.org. The BLI data is in datasets/lifesat/oecd_bli.csv (data from 2020), and the GDP per capita data is in datasets/lifesat/gdp_per_capita.csv (data up to 2020).\nIf you want to grab the latest versions, please feel free to do so. However, there may be some changes (e.g., in the column names, or different countries missing data), so be prepared to have to tweak the code.\n\nimport urllib.request\n\ndatapath = Path() / \"datasets\" / \"lifesat\"\ndatapath.mkdir(parents=True, exist_ok=True)\n\ndata_root = \"https://github.com/ageron/data/raw/main/\"\nfor filename in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n    if not (datapath / filename).is_file():\n        print(\"Downloading\", filename)\n        url = data_root + \"lifesat/\" + filename\n        urllib.request.urlretrieve(url, datapath / filename)\n\nDownloading oecd_bli.csv\nDownloading gdp_per_capita.csv\n\n\n\noecd_bli = pd.read_csv(datapath / \"oecd_bli.csv\")\ngdp_per_capita = pd.read_csv(datapath / \"gdp_per_capita.csv\")\n\nPreprocess the GDP per capita data to keep only the year 2020:\n\ngdp_year = 2020\ngdppc_col = \"GDP per capita (USD)\"\nlifesat_col = \"Life satisfaction\"\n\ngdp_per_capita = gdp_per_capita[gdp_per_capita[\"Year\"] == gdp_year]\ngdp_per_capita = gdp_per_capita.drop([\"Code\", \"Year\"], axis=1)\ngdp_per_capita.columns = [\"Country\", gdppc_col]\ngdp_per_capita.set_index(\"Country\", inplace=True)\n\ngdp_per_capita.head()\n\n\n\n\n\n\n\n\nGDP per capita (USD)\n\n\nCountry\n\n\n\n\n\nAfghanistan\n1978.961579\n\n\nAfrica Eastern and Southern\n3387.594670\n\n\nAfrica Western and Central\n4003.158913\n\n\nAlbania\n13295.410885\n\n\nAlgeria\n10681.679297\n\n\n\n\n\n\n\nPreprocess the OECD BLI data to keep only the Life satisfaction column:\n\noecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\noecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n\noecd_bli.head()\n\n\n\n\n\n\n\nIndicator\nAir pollution\nDwellings without basic facilities\nEducational attainment\nEmployees working very long hours\nEmployment rate\nFeeling safe walking alone at night\nHomicide rate\nHousehold net adjusted disposable income\nHousehold net wealth\nHousing expenditure\n...\nPersonal earnings\nQuality of support network\nRooms per person\nSelf-reported health\nStakeholder engagement for developing regulations\nStudent skills\nTime devoted to leisure and personal care\nVoter turnout\nWater quality\nYears in education\n\n\nCountry\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAustralia\n5.0\nNaN\n81.0\n13.04\n73.0\n63.5\n1.1\n32759.0\n427064.0\n20.0\n...\n49126.0\n95.0\nNaN\n85.0\n2.7\n502.0\n14.35\n91.0\n93.0\n21.0\n\n\nAustria\n16.0\n0.9\n85.0\n6.66\n72.0\n80.6\n0.5\n33541.0\n308325.0\n21.0\n...\n50349.0\n92.0\n1.6\n70.0\n1.3\n492.0\n14.55\n80.0\n92.0\n17.0\n\n\nBelgium\n15.0\n1.9\n77.0\n4.75\n63.0\n70.1\n1.0\n30364.0\n386006.0\n21.0\n...\n49675.0\n91.0\n2.2\n74.0\n2.0\n503.0\n15.70\n89.0\n84.0\n19.3\n\n\nBrazil\n10.0\n6.7\n49.0\n7.13\n61.0\n35.6\n26.7\nNaN\nNaN\nNaN\n...\nNaN\n90.0\nNaN\nNaN\n2.2\n395.0\nNaN\n79.0\n73.0\n16.2\n\n\nCanada\n7.0\n0.2\n91.0\n3.69\n73.0\n82.2\n1.3\n30854.0\n423849.0\n22.0\n...\n47622.0\n93.0\n2.6\n88.0\n2.9\n523.0\n14.56\n68.0\n91.0\n17.3\n\n\n\n\n5 rows × 24 columns\n\n\n\nNow let’s merge the life satisfaction data and the GDP per capita data, keeping only the GDP per capita and Life satisfaction columns:\n\nfull_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n                              left_index=True, right_index=True)\nfull_country_stats.sort_values(by=gdppc_col, inplace=True)\nfull_country_stats = full_country_stats[[gdppc_col, lifesat_col]]\n\nfull_country_stats.head()\n\n\n\n\n\n\n\n\nGDP per capita (USD)\nLife satisfaction\n\n\nCountry\n\n\n\n\n\n\nSouth Africa\n11466.189672\n4.7\n\n\nColombia\n13441.492952\n6.3\n\n\nBrazil\n14063.982505\n6.4\n\n\nMexico\n17887.750736\n6.5\n\n\nChile\n23324.524751\n6.5\n\n\n\n\n\n\n\nTo illustrate the risk of overfitting, I use only part of the data in most figures (all countries with a GDP per capita between min_gdp and max_gdp). Later in the chapter I reveal the missing countries, and show that they don’t follow the same linear trend at all.\n\nmin_gdp = 23_500\nmax_gdp = 62_500\n\ncountry_stats = full_country_stats[(full_country_stats[gdppc_col] &gt;= min_gdp) &\n                                   (full_country_stats[gdppc_col] &lt;= max_gdp)]\ncountry_stats.head()\n\n\n\n\n\n\n\n\nGDP per capita (USD)\nLife satisfaction\n\n\nCountry\n\n\n\n\n\n\nRussia\n26456.387938\n5.8\n\n\nGreece\n27287.083401\n5.4\n\n\nTurkey\n28384.987785\n5.5\n\n\nLatvia\n29932.493910\n5.9\n\n\nHungary\n31007.768407\n5.6\n\n\n\n\n\n\n\n\ncountry_stats.to_csv(datapath / \"lifesat.csv\")\nfull_country_stats.to_csv(datapath / \"lifesat_full.csv\")\n\n\ncountry_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n                   x=gdppc_col, y=lifesat_col)\n\nmin_life_sat = 4\nmax_life_sat = 9\n\nposition_text = {\n    \"Turkey\": (29_500, 4.2),\n    \"Hungary\": (28_000, 6.9),\n    \"France\": (40_000, 5),\n    \"New Zealand\": (28_000, 8.2),\n    \"Australia\": (50_000, 5.5),\n    \"United States\": (59_000, 5.3),\n    \"Denmark\": (46_000, 8.5)\n}\n\nfor country, pos_text in position_text.items():\n    pos_data_x = country_stats[gdppc_col].loc[country]\n    pos_data_y = country_stats[lifesat_col].loc[country]\n    country = \"U.S.\" if country == \"United States\" else country\n    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n                 xytext=pos_text, fontsize=12,\n                 arrowprops=dict(facecolor='black', width=0.5,\n                                 shrink=0.08, headwidth=5))\n    plt.plot(pos_data_x, pos_data_y, \"ro\")\n\nplt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n\nsave_fig('money_happy_scatterplot')\nplt.show()\n\n\n\n\n\nhighlighted_countries = country_stats.loc[list(position_text.keys())]\nhighlighted_countries[[gdppc_col, lifesat_col]].sort_values(by=gdppc_col)\n\n\n\n\n\n\n\n\nGDP per capita (USD)\nLife satisfaction\n\n\nCountry\n\n\n\n\n\n\nTurkey\n28384.987785\n5.5\n\n\nHungary\n31007.768407\n5.6\n\n\nFrance\n42025.617373\n6.5\n\n\nNew Zealand\n42404.393738\n7.3\n\n\nAustralia\n48697.837028\n7.3\n\n\nDenmark\n55938.212809\n7.6\n\n\nUnited States\n60235.728492\n6.9\n\n\n\n\n\n\n\n\ncountry_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n                   x=gdppc_col, y=lifesat_col)\n\nX = np.linspace(min_gdp, max_gdp, 1000)\n\nw1, w2 = 4.2, 0\nplt.plot(X, w1 + w2 * 1e-5 * X, \"r\")\nplt.text(40_000, 4.9, fr\"$\\theta_0 = {w1}$\", color=\"r\")\nplt.text(40_000, 4.4, fr\"$\\theta_1 = {w2}$\", color=\"r\")\n\nw1, w2 = 10, -9\nplt.plot(X, w1 + w2 * 1e-5 * X, \"g\")\nplt.text(26_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"g\")\nplt.text(26_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"g\")\n\nw1, w2 = 3, 8\nplt.plot(X, w1 + w2 * 1e-5 * X, \"b\")\nplt.text(48_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"b\")\nplt.text(48_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"b\")\n\nplt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n\nsave_fig('tweaking_model_params_plot')\nplt.show()\n\n\n\n\n\nfrom sklearn import linear_model\n\nX_sample = country_stats[[gdppc_col]].values\ny_sample = country_stats[[lifesat_col]].values\n\nlin1 = linear_model.LinearRegression()\nlin1.fit(X_sample, y_sample)\n\nt0, t1 = lin1.intercept_[0], lin1.coef_[0][0]\nprint(f\"θ0={t0:.2f}, θ1={t1:.2e}\")\n\nθ0=3.75, θ1=6.78e-05\n\n\n\ncountry_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n                   x=gdppc_col, y=lifesat_col)\n\nX = np.linspace(min_gdp, max_gdp, 1000)\nplt.plot(X, t0 + t1 * X, \"b\")\n\nplt.text(max_gdp - 20_000, min_life_sat + 1.9,\n         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\nplt.text(max_gdp - 20_000, min_life_sat + 1.3,\n         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n\nplt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n\nsave_fig('best_fit_model_plot')\nplt.show()\n\n\n\n\n\ncyprus_gdp_per_capita = gdp_per_capita[gdppc_col].loc[\"Cyprus\"]\ncyprus_gdp_per_capita\n\n37655.1803457421\n\n\n\ncyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0, 0]\ncyprus_predicted_life_satisfaction\n\n6.301656332738056\n\n\n\ncountry_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n                   x=gdppc_col, y=lifesat_col)\n\nX = np.linspace(min_gdp, max_gdp, 1000)\nplt.plot(X, t0 + t1 * X, \"b\")\n\nplt.text(min_gdp + 22_000, max_life_sat - 1.1,\n         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\nplt.text(min_gdp + 22_000, max_life_sat - 0.6,\n         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n\nplt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita],\n         [min_life_sat, cyprus_predicted_life_satisfaction], \"r--\")\nplt.text(cyprus_gdp_per_capita + 1000, 5.0,\n         fr\"Prediction = {cyprus_predicted_life_satisfaction:.2f}\", color=\"r\")\nplt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n\nplt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n\nplt.show()\n\n\n\n\n\nmissing_data = full_country_stats[(full_country_stats[gdppc_col] &lt; min_gdp) |\n                                  (full_country_stats[gdppc_col] &gt; max_gdp)]\nmissing_data\n\n\n\n\n\n\n\n\nGDP per capita (USD)\nLife satisfaction\n\n\nCountry\n\n\n\n\n\n\nSouth Africa\n11466.189672\n4.7\n\n\nColombia\n13441.492952\n6.3\n\n\nBrazil\n14063.982505\n6.4\n\n\nMexico\n17887.750736\n6.5\n\n\nChile\n23324.524751\n6.5\n\n\nNorway\n63585.903514\n7.6\n\n\nSwitzerland\n68393.306004\n7.5\n\n\nIreland\n89688.956958\n7.0\n\n\nLuxembourg\n110261.157353\n6.9\n\n\n\n\n\n\n\n\nposition_text_missing_countries = {\n    \"South Africa\": (20_000, 4.2),\n    \"Colombia\": (6_000, 8.2),\n    \"Brazil\": (18_000, 7.8),\n    \"Mexico\": (24_000, 7.4),\n    \"Chile\": (30_000, 7.0),\n    \"Norway\": (51_000, 6.2),\n    \"Switzerland\": (62_000, 5.7),\n    \"Ireland\": (81_000, 5.2),\n    \"Luxembourg\": (92_000, 4.7),\n}\n\n\nfull_country_stats.plot(kind='scatter', figsize=(8, 3),\n                        x=gdppc_col, y=lifesat_col, grid=True)\n\nfor country, pos_text in position_text_missing_countries.items():\n    pos_data_x, pos_data_y = missing_data.loc[country]\n    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n                 xytext=pos_text, fontsize=12,\n                 arrowprops=dict(facecolor='black', width=0.5,\n                                 shrink=0.08, headwidth=5))\n    plt.plot(pos_data_x, pos_data_y, \"rs\")\n\nX = np.linspace(0, 115_000, 1000)\nplt.plot(X, t0 + t1 * X, \"b:\")\n\nlin_reg_full = linear_model.LinearRegression()\nXfull = np.c_[full_country_stats[gdppc_col]]\nyfull = np.c_[full_country_stats[lifesat_col]]\nlin_reg_full.fit(Xfull, yfull)\n\nt0full, t1full = lin_reg_full.intercept_[0], lin_reg_full.coef_[0][0]\nX = np.linspace(0, 115_000, 1000)\nplt.plot(X, t0full + t1full * X, \"k\")\n\nplt.axis([0, 115_000, min_life_sat, max_life_sat])\n\nsave_fig('representative_training_data_scatterplot')\nplt.show()\n\n\n\n\n\nfrom sklearn import preprocessing\nfrom sklearn import pipeline\n\nfull_country_stats.plot(kind='scatter', figsize=(8, 3),\n                        x=gdppc_col, y=lifesat_col, grid=True)\n\npoly = preprocessing.PolynomialFeatures(degree=10, include_bias=False)\nscaler = preprocessing.StandardScaler()\nlin_reg2 = linear_model.LinearRegression()\n\npipeline_reg = pipeline.Pipeline([\n    ('poly', poly),\n    ('scal', scaler),\n    ('lin', lin_reg2)])\npipeline_reg.fit(Xfull, yfull)\ncurve = pipeline_reg.predict(X[:, np.newaxis])\nplt.plot(X, curve)\n\nplt.axis([0, 115_000, min_life_sat, max_life_sat])\n\nsave_fig('overfitting_model_plot')\nplt.show()\n\n\n\n\n\nw_countries = [c for c in full_country_stats.index if \"W\" in c.upper()]\nfull_country_stats.loc[w_countries][lifesat_col]\n\nCountry\nNew Zealand    7.3\nSweden         7.3\nNorway         7.6\nSwitzerland    7.5\nName: Life satisfaction, dtype: float64\n\n\n\nall_w_countries = [c for c in gdp_per_capita.index if \"W\" in c.upper()]\ngdp_per_capita.loc[all_w_countries].sort_values(by=gdppc_col)\n\n\n\n\n\n\n\n\nGDP per capita (USD)\n\n\nCountry\n\n\n\n\n\nMalawi\n1486.778248\n\n\nRwanda\n2098.710362\n\n\nZimbabwe\n2744.690758\n\n\nAfrica Western and Central\n4003.158913\n\n\nPapua New Guinea\n4101.218882\n\n\nLower middle income\n6722.809932\n\n\nEswatini\n8392.717564\n\n\nLow & middle income\n10293.855325\n\n\nArab World\n13753.707307\n\n\nBotswana\n16040.008473\n\n\nWorld\n16194.040310\n\n\nNew Zealand\n42404.393738\n\n\nSweden\n50683.323510\n\n\nNorway\n63585.903514\n\n\nSwitzerland\n68393.306004\n\n\n\n\n\n\n\n\ncountry_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col, figsize=(8, 3))\nmissing_data.plot(kind='scatter', x=gdppc_col, y=lifesat_col,\n                  marker=\"s\", color=\"r\", grid=True, ax=plt.gca())\n\nX = np.linspace(0, 115_000, 1000)\nplt.plot(X, t0 + t1*X, \"b:\", label=\"Linear model on partial data\")\nplt.plot(X, t0full + t1full * X, \"k-\", label=\"Linear model on all data\")\n\nridge = linear_model.Ridge(alpha=10**9.5)\nX_sample = country_stats[[gdppc_col]]\ny_sample = country_stats[[lifesat_col]]\nridge.fit(X_sample, y_sample)\nt0ridge, t1ridge = ridge.intercept_[0], ridge.coef_[0][0]\nplt.plot(X, t0ridge + t1ridge * X, \"b--\",\n         label=\"Regularized linear model on partial data\")\nplt.legend(loc=\"lower right\")\n\nplt.axis([0, 115_000, min_life_sat, max_life_sat])\n\nsave_fig('ridge_model_plot')\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yoseph’s ML Blog",
    "section": "",
    "text": "Setup\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear and nonlinear regression\n\n\n\nRegression\n\n\n\nline on scatter plot\n\n\n\n\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\nDBScan\n\n\nClustering\n\n\n\nDBSCAN labels for scatter plot\n\n\n\n\n\n\nOct 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification\n\n\n\nROC\n\n\nPR\n\n\nConfusion Matrix\n\n\nClassification\n\n\n\nROC, PR, Confusion Matrix\n\n\n\n\n\n\nOct 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipal Component Analysis\n\n\n\nHistogram\n\n\nProbability theory\n\n\nrandom variables\n\n\nPCA\n\n\n\nWhat’s PCA, when and how to use it in Machine Learnging\n\n\n\n\n\n\nOct 30, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]